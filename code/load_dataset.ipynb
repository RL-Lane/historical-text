{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8668f3a7-e4b4-41c1-b01e-7600ba825a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "\n",
    "from PIL import Image, ImageOps\n",
    "import random\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchvision import transforms\n",
    "import torchvision.transforms.functional as TF\n",
    "import torchvision.models as models\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "from blf_torch import BilateralFilter, DEVICE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0696f175-691b-48ac-8bb5-4027c1b1b813",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading image metadata... done\n"
     ]
    }
   ],
   "source": [
    "# print('check for train dataset rows:')\n",
    "with open('train_dataset.csv', mode='r', encoding='utf-8') as file:\n",
    "    reader = csv.DictReader(file)  # Reads the CSV into a list of dictionaries\n",
    "    train = [{**row, 'label_num': int(row['label_num'])} for row in reader]  # Convert label_num to int\n",
    "# Print the dictionary\n",
    "# for row in train[:3]:\n",
    "#     print(row)\n",
    "\n",
    "print('loading image metadata...', end='')\n",
    "# print('check for test dataset rows:')\n",
    "with open('test_dataset.csv', mode='r', encoding='utf-8') as file:\n",
    "    reader = csv.DictReader(file)  # Reads the CSV into a list of dictionaries\n",
    "    test = [{**row, 'label_num': int(row['label_num'])} for row in reader]  # Convert label_num to int\n",
    "# Print the dictionary\n",
    "# for row in test[:3]:\n",
    "#     print(row)\n",
    "\n",
    "# These datasets were pre-shuffled, so we should be able to take a small sample for testing out algorithms.\n",
    "mini_length = 100\n",
    "train_mini = train[:mini_length]\n",
    "# print('\\ntrain_mini length:',len(train_mini))\n",
    "\n",
    "print(' done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ecf8cd68-e4f3-480d-80d3-f81ba1219c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://clamm.irht.cnrs.fr/icdar-2017/data-set/\n",
    "\n",
    "script_conversion = {\n",
    "    '1':\"Caroline\",\n",
    "    '2':\"Cursiva\",\n",
    "    '3':\"Half Uncial\",\n",
    "    '4':\"Humanistic\",\n",
    "    '5':\"Humanistic Cursive\",\n",
    "    '6':\"Hybrida\",\n",
    "    '7':\"Praegothica\",\n",
    "    '8':\"Semihybrida\",\n",
    "    '9':\"Semitextualis\",\n",
    "    '10':\"Southern Textualis\",\n",
    "    '11':\"Textualis\",\n",
    "    '12':\"Uncial\"\n",
    "}\n",
    "\n",
    "reverse_script_conversion = {v: int(k) for k, v in script_conversion.items()}\n",
    "\n",
    "def convert_to_script(label_number):\n",
    "    \"\"\"\n",
    "    Convert a label number (e.g., '11') to its script name.\n",
    "    \"\"\"\n",
    "    return script_conversion.get(str(label_number), \"Unknown\")\n",
    "\n",
    "def clean_label(label):\n",
    "    # Replace '_' with ' ', convert to title case, and strip spaces\n",
    "    return label.replace(\"_\", \" \").title().strip()\n",
    "\n",
    "def convert_to_number(script_name):\n",
    "    \"\"\"\n",
    "    Convert a script name (e.g., 'Textualis') to its corresponding number.\n",
    "    \"\"\"\n",
    "    cleaned_script_name = clean_label(script_name)\n",
    "    return reverse_script_conversion.get(cleaned_script_name, -1)\n",
    "\n",
    "def build_dataset(csv_path, image_folder, icdar = 0):\n",
    "\n",
    "\n",
    "        # Routine cleaning function\n",
    "\n",
    "    \n",
    "    # Step 1: Read the CSV and store labels in a dictionary\n",
    "    label_dict = {}\n",
    "    with open(csv_path, mode='r') as csvfile:\n",
    "        reader = csv.reader(csvfile, delimiter=';')\n",
    "        # Assuming the first row is header, skip it if needed\n",
    "        next(reader)\n",
    "        for row in reader:\n",
    "            filename = row[0+icdar]  # Adjust index based on your CSV structure\n",
    "            label = row[1+icdar]  # Adjust index based on your CSV structure\n",
    "            label = str(label)\n",
    "            label = clean_label(script_conversion.get(label, label))\n",
    "            if (label in script_conversion):\n",
    "                label = script_conversion[label]\n",
    "            label_dict[filename] = label\n",
    "\n",
    "    # Step 2: Match images to labels and store the full path\n",
    "    dataset = {}\n",
    "    with os.scandir(image_folder) as entries:\n",
    "        for entry in entries:\n",
    "            if entry.is_file():\n",
    "                image_id = entry.name\n",
    "                \n",
    "                if image_id in label_dict:  # Only add if we have a matching label\n",
    "                    dataset[image_id] = {\n",
    "                        'filepath': os.path.join(image_folder, entry.name),\n",
    "                        'label': label_dict[image_id],\n",
    "                        'label_num': reverse_script_conversion[label_dict[image_id]]\n",
    "                    }\n",
    "\n",
    "    print(f\"Dataset created with {len(dataset)} items.\")\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "387647c1-1634-4d65-b0d0-e7e13dd5372e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class AddGaussianNoise:\n",
    "    def __init__(self, mean=0.0, std=0.1):\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "\n",
    "    def __call__(self, image):\n",
    "        is_pillow = isinstance(image, Image.Image)\n",
    "        if is_pillow:\n",
    "            image = TF.to_tensor(image)\n",
    "        noise = torch.randn_like(image) * self.std + self.mean\n",
    "        noisy_image = torch.clamp(image + noise, 0, 1)\n",
    "        if is_pillow:\n",
    "            return TF.to_pil_image(noisy_image)\n",
    "        return noisy_image\n",
    "\n",
    "\n",
    "class AddSpeckleNoise:\n",
    "    def __init__(self, mean=0.0, std=0.1):\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "\n",
    "    def __call__(self, image):\n",
    "        is_pillow = isinstance(image, Image.Image)\n",
    "        if is_pillow:\n",
    "            image = TF.to_tensor(image)\n",
    "        noise = torch.randn_like(image) * self.std + self.mean\n",
    "        noisy_image = torch.clamp(image + image * noise, 0, 1)\n",
    "        if is_pillow:\n",
    "            return TF.to_pil_image(noisy_image)\n",
    "        return noisy_image\n",
    "\n",
    "\n",
    "class AddSaltAndPepperNoise:\n",
    "    def __init__(self, amount=0.02, salt_vs_pepper=0.5):\n",
    "        self.amount = amount\n",
    "        self.salt_vs_pepper = salt_vs_pepper\n",
    "\n",
    "    def __call__(self, image):\n",
    "        is_pillow = isinstance(image, Image.Image)\n",
    "        if is_pillow:\n",
    "            image = TF.to_tensor(image)\n",
    "        noisy_image = image.clone()\n",
    "        num_pixels = int(self.amount * image.numel())\n",
    "        salt_indices = torch.randint(0, image.numel(), (int(num_pixels * self.salt_vs_pepper),), device=image.device)\n",
    "        pepper_indices = torch.randint(0, image.numel(), (int(num_pixels * (1 - self.salt_vs_pepper)),), device=image.device)\n",
    "        noisy_image.view(-1)[salt_indices] = 1.0\n",
    "        noisy_image.view(-1)[pepper_indices] = 0.0\n",
    "        if is_pillow:\n",
    "            return TF.to_pil_image(noisy_image)\n",
    "        return noisy_image\n",
    "\n",
    "# Prepare a bilateral filter class for the pipeline.\n",
    "# blf() above uses CPU and is too slow.  Below uses CUDA if available (DEVICE).\n",
    "class ApplyBilateralFilter:\n",
    "    def __init__(self, kernel_size=5, sigma_space=5, sigma_color=0.1):\n",
    "        self.kernel_size = kernel_size\n",
    "        self.sigma_space = sigma_space\n",
    "        self.sigma_color = sigma_color\n",
    "\n",
    "    def __call__(self, img):\n",
    "        # Convert PIL image to tensor\n",
    "        img_tensor = transforms.ToTensor()(img).unsqueeze(0).to(DEVICE)\n",
    "\n",
    "        # Initialize the bilateral filter (dynamic size detection)\n",
    "        bilateral_filter = BilateralFilter(\n",
    "            channels=img_tensor.shape[1],\n",
    "            k=self.kernel_size,\n",
    "            height=img_tensor.shape[2],\n",
    "            width=img_tensor.shape[3],\n",
    "            sigma_space=self.sigma_space,\n",
    "            sigma_color=self.sigma_color,\n",
    "            device=DEVICE\n",
    "        )\n",
    "\n",
    "        # Apply the filter\n",
    "        with torch.no_grad():\n",
    "            filtered_tensor = bilateral_filter(img_tensor)\n",
    "\n",
    "        # Convert the tensor back to a PIL image\n",
    "        filtered_img = transforms.ToPILImage()(filtered_tensor.squeeze(0).to(DEVICE))\n",
    "        return filtered_img\n",
    "        # return filtered_tensor\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# geometric transform\n",
    "transform_pipeline = transforms.Compose([\n",
    "    # geometric\n",
    "    transforms.RandomApply(      [transforms.RandomAffine(degrees=0, shear=10, interpolation=Image.BICUBIC)              ], p=0.5)\n",
    "    ,transforms.RandomApply(     [transforms.RandomRotation(degrees=15, interpolation=Image.BICUBIC)                     ], p=0.5)\n",
    "    ,transforms.RandomApply(     [transforms.RandomPerspective(distortion_scale=0.2, p=0.3, interpolation=Image.BICUBIC) ], p=0.2)\n",
    "    ,transforms.RandomResizedCrop(\n",
    "        size=(300,300),\n",
    "        scale=(0.8, 1.2),\n",
    "        ratio=(0.8, 1.2),\n",
    "        interpolation=Image.BICUBIC\n",
    "    )\n",
    "    ,ApplyBilateralFilter(kernel_size=5, sigma_space=5, sigma_color=0.1)\n",
    "\n",
    "    # color / photo effects\n",
    "    ,transforms.RandomApply(     [transforms.GaussianBlur(kernel_size=(3,3))                                             ], p=0.2)\n",
    "\n",
    "    ,transforms.RandomApply([transforms.RandomChoice([\n",
    "                            AddGaussianNoise(mean=0.0, std=0.1),\n",
    "                            AddSpeckleNoise(mean=0.0, std=0.1),\n",
    "                            AddSaltAndPepperNoise(amount=0.02, salt_vs_pepper=0.5)\n",
    "                        ])                                                                                               ], p = 0.25)\n",
    "\n",
    "\n",
    "    \n",
    "    ,transforms.CenterCrop((224,224)) # ResNet50 expects 224x224\n",
    "    ,transforms.ToTensor()\n",
    "    ,transforms.Lambda(lambda x: x.repeat(3, 1, 1))  # Convert 1-channel grayscale to 3-channel\n",
    "    ,transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Standard normalization for ResNet50\n",
    "])\n",
    "\n",
    "test_transform_pipeline = transforms.Compose([\n",
    "    # geometric\n",
    "    ApplyBilateralFilter(kernel_size=5, sigma_space=5, sigma_color=0.1)\n",
    "\n",
    "    \n",
    "    ,transforms.CenterCrop((224,224)) # ResNet50 expects 224x224\n",
    "    ,transforms.ToTensor()\n",
    "    ,transforms.Lambda(lambda x: x.repeat(3, 1, 1))  # Convert 1-channel grayscale to 3-channel\n",
    "    ,transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Standard normalization for ResNet50\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "minimal_preprocessing_pipeline = transforms.Compose([\n",
    "    # geometric\n",
    "\n",
    "    transforms.CenterCrop((224,224)) # ResNet50 expects 224x224\n",
    "    ,transforms.ToTensor()\n",
    "    ,transforms.Lambda(lambda x: x.repeat(3, 1, 1))  # Convert 1-channel grayscale to 3-channel\n",
    "    ,transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Standard normalization for ResNet50\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bcd28d61-e74f-4e2a-aecf-df208f3cc415",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class ScriptDataset(Dataset):\n",
    "    def __init__(self, dataset, transform=None, multiplier=10, max_size=None):\n",
    "        \"\"\"\n",
    "        dataset: List of dicts, each containing 'filepath', 'label', and 'label_num'\n",
    "        transform: torchvision transforms (augmentations + preprocessing)\n",
    "        multiplier: Number of times each raw image is virtually repeated\n",
    "        max_size: Upper limit on the dataset size (optional)\n",
    "        \"\"\"\n",
    "        self.dataset = dataset  # Now a list of dicts, not a dict itself\n",
    "        self.transform = transform\n",
    "        self.multiplier = multiplier\n",
    "        \n",
    "        # Compute virtual dataset size\n",
    "        self.virtual_size = len(self.dataset) * self.multiplier\n",
    "\n",
    "        # Apply max_size limit if provided\n",
    "        if max_size is not None:\n",
    "            self.virtual_size = min(self.virtual_size, max_size)\n",
    "\n",
    "    def crop_sample(self, image, crop_dim=300):\n",
    "        \"\"\"Crop a random 300x300 region.\"\"\"\n",
    "        img_width, img_height = image.size\n",
    "        margin_x = int(img_width * 0.05)\n",
    "        margin_y = int(img_height * 0.05)\n",
    "        max_x = img_width - crop_dim - margin_x\n",
    "        max_y = img_height - crop_dim - margin_y\n",
    "\n",
    "        left = random.randint(margin_x, max_x)\n",
    "        upper = random.randint(margin_y, max_y)\n",
    "        crop_box = (left, upper, left + crop_dim, upper + crop_dim)\n",
    "        return image.crop(crop_box)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Return the virtual dataset size (capped at max_size if set).\"\"\"\n",
    "        return self.virtual_size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Map virtual index back to the original dataset\n",
    "        real_idx = idx % len(self.dataset)\n",
    "        row = self.dataset[real_idx]\n",
    "\n",
    "        # Load image\n",
    "        image = Image.open(row[\"filepath\"]).convert(\"L\")\n",
    "\n",
    "        # Apply random crop\n",
    "        image = self.crop_sample(image)\n",
    "\n",
    "        # Apply transforms (if any)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        #  Python counts from 0, but the dataset counts from 1.  We will have to account for this later\n",
    "        corrected_label = row['label_num'] - 1\n",
    "        # Return image and numerical label as a tuple\n",
    "        return image, corrected_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5e966c0-5533-4cb4-bfca-5436617fa3b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n"
     ]
    }
   ],
   "source": [
    "script_dataset = ScriptDataset(train_mini, transform=transform_pipeline, multiplier=20, max_size=2_000)\n",
    "print(len(script_dataset))\n",
    "\n",
    "data_loader = DataLoader(script_dataset, batch_size=4, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "029e6772-7a6c-4348-aae6-7a60b15cad08",
   "metadata": {},
   "source": [
    "print(\"Image Tensor Shape:\", img_tensor.shape)  # Expected: [1, C, H, W]\n",
    "print(\"Using Device:\", DEVICE)\n",
    "\n",
    "# Debug BilateralFilter initialization\n",
    "bilateral_filter = BilateralFilter(\n",
    "    channels=img_tensor.shape[1],\n",
    "    k=self.kernel_size,\n",
    "    height=img_tensor.shape[2],\n",
    "    width=img_tensor.shape[3],\n",
    "    sigma_space=self.sigma_space,\n",
    "    sigma_color=self.sigma_color,\n",
    "    device=DEVICE\n",
    ")\n",
    "print(\"Bilateral filter initialized successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8006f51d-387e-4c60-a909-a3f264b7a7d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/rmirza/.conda/envs/datascience/lib/python3.13/site-packages/torch/functional.py:539: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /pytorch/aten/src/ATen/native/TensorShape.cpp:3637.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[tensor([[[[ 1.6495,  1.6324,  1.6153,  ..., -0.1314,  0.9303,  1.0844],\n",
       "           [ 1.6495,  1.6324,  1.5982,  ..., -0.1828,  0.8789,  1.0502],\n",
       "           [ 1.6324,  1.6153,  1.5810,  ..., -0.8335,  0.5878,  1.0331],\n",
       "           ...,\n",
       "           [ 1.4098,  1.4098,  1.3927,  ...,  1.4098,  1.4269,  1.4440],\n",
       "           [ 1.3927,  1.3755,  1.3755,  ...,  1.4269,  1.4269,  1.4440],\n",
       "           [ 1.3584,  1.3584,  1.3584,  ...,  1.4440,  1.4269,  1.4440]],\n",
       " \n",
       "          [[ 1.8158,  1.7983,  1.7808,  ..., -0.0049,  1.0805,  1.2381],\n",
       "           [ 1.8158,  1.7983,  1.7633,  ..., -0.0574,  1.0280,  1.2031],\n",
       "           [ 1.7983,  1.7808,  1.7458,  ..., -0.7227,  0.7304,  1.1856],\n",
       "           ...,\n",
       "           [ 1.5707,  1.5707,  1.5532,  ...,  1.5707,  1.5882,  1.6057],\n",
       "           [ 1.5532,  1.5357,  1.5357,  ...,  1.5882,  1.5882,  1.6057],\n",
       "           [ 1.5182,  1.5182,  1.5182,  ...,  1.6057,  1.5882,  1.6057]],\n",
       " \n",
       "          [[ 2.0300,  2.0125,  1.9951,  ...,  0.2173,  1.2980,  1.4548],\n",
       "           [ 2.0300,  2.0125,  1.9777,  ...,  0.1651,  1.2457,  1.4200],\n",
       "           [ 2.0125,  1.9951,  1.9603,  ..., -0.4973,  0.9494,  1.4025],\n",
       "           ...,\n",
       "           [ 1.7860,  1.7860,  1.7685,  ...,  1.7860,  1.8034,  1.8208],\n",
       "           [ 1.7685,  1.7511,  1.7511,  ...,  1.8034,  1.8034,  1.8208],\n",
       "           [ 1.7337,  1.7337,  1.7337,  ...,  1.8208,  1.8034,  1.8208]]],\n",
       " \n",
       " \n",
       "         [[[-1.2274, -1.2617, -1.2788,  ...,  1.4612,  1.5125,  1.5639],\n",
       "           [-1.2274, -1.2617, -1.2788,  ...,  1.4954,  1.5297,  1.5810],\n",
       "           [-1.2103, -1.2445, -1.2617,  ...,  1.5468,  1.5810,  1.5982],\n",
       "           ...,\n",
       "           [ 1.6324,  1.6495,  1.6667,  ...,  1.4440,  1.4440,  1.4269],\n",
       "           [ 1.6153,  1.6495,  1.6495,  ...,  1.4954,  1.4612,  1.4612],\n",
       "           [ 1.5810,  1.6324,  1.6495,  ...,  1.5125,  1.4783,  1.4612]],\n",
       " \n",
       "          [[-1.1253, -1.1604, -1.1779,  ...,  1.6232,  1.6758,  1.7283],\n",
       "           [-1.1253, -1.1604, -1.1779,  ...,  1.6583,  1.6933,  1.7458],\n",
       "           [-1.1078, -1.1429, -1.1604,  ...,  1.7108,  1.7458,  1.7633],\n",
       "           ...,\n",
       "           [ 1.7983,  1.8158,  1.8333,  ...,  1.6057,  1.6057,  1.5882],\n",
       "           [ 1.7808,  1.8158,  1.8158,  ...,  1.6583,  1.6232,  1.6232],\n",
       "           [ 1.7458,  1.7983,  1.8158,  ...,  1.6758,  1.6408,  1.6232]],\n",
       " \n",
       "          [[-0.8981, -0.9330, -0.9504,  ...,  1.8383,  1.8905,  1.9428],\n",
       "           [-0.8981, -0.9330, -0.9504,  ...,  1.8731,  1.9080,  1.9603],\n",
       "           [-0.8807, -0.9156, -0.9330,  ...,  1.9254,  1.9603,  1.9777],\n",
       "           ...,\n",
       "           [ 2.0125,  2.0300,  2.0474,  ...,  1.8208,  1.8208,  1.8034],\n",
       "           [ 1.9951,  2.0300,  2.0300,  ...,  1.8731,  1.8383,  1.8383],\n",
       "           [ 1.9603,  2.0125,  2.0300,  ...,  1.8905,  1.8557,  1.8383]]],\n",
       " \n",
       " \n",
       "         [[[ 1.6153,  1.5982,  1.5468,  ...,  1.7694,  1.7694,  1.7865],\n",
       "           [ 1.5982,  1.5639,  1.5125,  ...,  1.7865,  1.7865,  1.7865],\n",
       "           [ 1.5639,  1.5125,  1.4269,  ...,  1.7865,  1.8037,  1.8037],\n",
       "           ...,\n",
       "           [-2.1179, -2.0837, -2.0837,  ...,  1.7694,  1.7694,  1.7694],\n",
       "           [-2.1179, -2.0837, -2.0665,  ...,  1.8037,  1.7865,  1.7865],\n",
       "           [-2.1179, -2.0837, -2.0665,  ...,  1.8037,  1.8037,  1.7865]],\n",
       " \n",
       "          [[ 1.7808,  1.7633,  1.7108,  ...,  1.9384,  1.9384,  1.9559],\n",
       "           [ 1.7633,  1.7283,  1.6758,  ...,  1.9559,  1.9559,  1.9559],\n",
       "           [ 1.7283,  1.6758,  1.5882,  ...,  1.9559,  1.9734,  1.9734],\n",
       "           ...,\n",
       "           [-2.0357, -2.0007, -2.0007,  ...,  1.9384,  1.9384,  1.9384],\n",
       "           [-2.0357, -2.0007, -1.9832,  ...,  1.9734,  1.9559,  1.9559],\n",
       "           [-2.0357, -2.0007, -1.9832,  ...,  1.9734,  1.9734,  1.9559]],\n",
       " \n",
       "          [[ 1.9951,  1.9777,  1.9254,  ...,  2.1520,  2.1520,  2.1694],\n",
       "           [ 1.9777,  1.9428,  1.8905,  ...,  2.1694,  2.1694,  2.1694],\n",
       "           [ 1.9428,  1.8905,  1.8034,  ...,  2.1694,  2.1868,  2.1868],\n",
       "           ...,\n",
       "           [-1.8044, -1.7696, -1.7696,  ...,  2.1520,  2.1520,  2.1520],\n",
       "           [-1.8044, -1.7696, -1.7522,  ...,  2.1868,  2.1694,  2.1694],\n",
       "           [-1.8044, -1.7696, -1.7522,  ...,  2.1868,  2.1868,  2.1694]]],\n",
       " \n",
       " \n",
       "         [[[ 1.9578,  1.9578,  1.9578,  ...,  1.9578,  1.9578,  1.9407],\n",
       "           [ 1.9749,  1.9749,  1.9749,  ...,  1.9578,  1.9578,  1.9407],\n",
       "           [ 1.9920,  1.9749,  1.9749,  ...,  1.9578,  1.9407,  1.9407],\n",
       "           ...,\n",
       "           [ 1.9064,  1.8722,  1.8550,  ...,  1.8208,  1.8037,  1.7865],\n",
       "           [ 1.8550,  1.7009,  1.5125,  ...,  1.8037,  1.7865,  1.7694],\n",
       "           [ 0.7933, -0.5596, -0.6623,  ...,  1.7694,  1.7694,  1.7352]],\n",
       " \n",
       "          [[ 2.1310,  2.1310,  2.1310,  ...,  2.1310,  2.1310,  2.1134],\n",
       "           [ 2.1485,  2.1485,  2.1485,  ...,  2.1310,  2.1310,  2.1134],\n",
       "           [ 2.1660,  2.1485,  2.1485,  ...,  2.1310,  2.1134,  2.1134],\n",
       "           ...,\n",
       "           [ 2.0784,  2.0434,  2.0259,  ...,  1.9909,  1.9734,  1.9559],\n",
       "           [ 2.0259,  1.8683,  1.6758,  ...,  1.9734,  1.9559,  1.9384],\n",
       "           [ 0.9405, -0.4426, -0.5476,  ...,  1.9384,  1.9384,  1.9034]],\n",
       " \n",
       "          [[ 2.3437,  2.3437,  2.3437,  ...,  2.3437,  2.3437,  2.3263],\n",
       "           [ 2.3611,  2.3611,  2.3611,  ...,  2.3437,  2.3437,  2.3263],\n",
       "           [ 2.3786,  2.3611,  2.3611,  ...,  2.3437,  2.3263,  2.3263],\n",
       "           ...,\n",
       "           [ 2.2914,  2.2566,  2.2391,  ...,  2.2043,  2.1868,  2.1694],\n",
       "           [ 2.2391,  2.0823,  1.8905,  ...,  2.1868,  2.1694,  2.1520],\n",
       "           [ 1.1585, -0.2184, -0.3230,  ...,  2.1520,  2.1520,  2.1171]]]]),\n",
       " tensor([ 1,  9,  0, 10])]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(data_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9d8c075-407d-4c57-8622-8112f466cb5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image batch shape: torch.Size([4, 3, 224, 224])\n",
      "Label batch shape: torch.Size([4])\n"
     ]
    }
   ],
   "source": [
    "sample_images, sample_labels = next(iter(data_loader))\n",
    "print(\"Image batch shape:\", sample_images.shape)  # Expected: [batch_size, 3, 224, 224]\n",
    "print(\"Label batch shape:\", sample_labels.shape)  # Expected: [batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3836f20-2fa0-485a-92a5-71946d6fc0fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/rmirza/.conda/envs/datascience/lib/python3.13/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/users/rmirza/.conda/envs/datascience/lib/python3.13/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([4, 1000])\n"
     ]
    }
   ],
   "source": [
    "model = models.resnet50(pretrained=False)\n",
    "# Run a forward pass with a single batch\n",
    "with torch.no_grad():\n",
    "    output = model(sample_images)  # Check if this runs without error\n",
    "\n",
    "print(\"Output shape:\", output.shape)  # Expected: [batch_size, 1000] (default ResNet output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e18cb511-260a-49d4-8c76-4054cb03c1c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample labels: tensor([5, 2, 4, 8])\n",
      "Label dtype: torch.int64\n",
      "Label min/max: 2 8\n"
     ]
    }
   ],
   "source": [
    "print(\"Sample labels:\", sample_labels)\n",
    "print(\"Label dtype:\", sample_labels.dtype)\n",
    "print(\"Label min/max:\", sample_labels.min().item(), sample_labels.max().item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ef580ab6-f2d9-4e53-895f-6089d58623c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/rmirza/.conda/envs/datascience/lib/python3.13/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.4872446060180664\n",
      "Loss: 2.5358476638793945\n",
      "Loss: 2.614347219467163\n",
      "Loss: 2.352200746536255\n",
      "Loss: 2.8540596961975098\n",
      "Loss: 2.2352347373962402\n",
      "Loss: 2.807258129119873\n",
      "Loss: 2.5036325454711914\n",
      "Loss: 2.4849510192871094\n",
      "Loss: 2.6718215942382812\n",
      "Loss: 2.6976802349090576\n",
      "Loss: 2.7805144786834717\n",
      "Loss: 2.541954278945923\n",
      "Loss: 2.1956281661987305\n",
      "Loss: 2.479978084564209\n",
      "Loss: 2.7356362342834473\n",
      "Loss: 2.354104995727539\n",
      "Loss: 2.0953011512756348\n",
      "Loss: 1.9145890474319458\n",
      "Loss: 2.730525255203247\n",
      "Loss: 2.3479676246643066\n",
      "Loss: 2.3844809532165527\n",
      "Loss: 2.253364324569702\n",
      "Loss: 2.542165517807007\n",
      "Loss: 2.2536568641662598\n",
      "Loss: 2.3144609928131104\n",
      "Loss: 1.752107858657837\n",
      "Loss: 2.331458330154419\n",
      "Loss: 2.1103110313415527\n",
      "Loss: 2.6560120582580566\n",
      "Loss: 2.0476701259613037\n",
      "Loss: 2.25929856300354\n",
      "Loss: 2.4025590419769287\n",
      "Loss: 1.6341776847839355\n",
      "Loss: 2.3846993446350098\n",
      "Loss: 2.529937267303467\n",
      "Loss: 2.833601951599121\n",
      "Loss: 1.904239296913147\n",
      "Loss: 2.957261085510254\n",
      "Loss: 2.4448046684265137\n",
      "Loss: 2.089660882949829\n",
      "Loss: 1.400378704071045\n",
      "Loss: 2.2545952796936035\n",
      "Loss: 2.910844087600708\n",
      "Loss: 2.4891271591186523\n",
      "Loss: 2.261725425720215\n",
      "Loss: 1.6954213380813599\n",
      "Loss: 2.254523277282715\n",
      "Loss: 1.9548381567001343\n",
      "Loss: 1.7904024124145508\n",
      "Loss: 1.9078426361083984\n",
      "Loss: 2.0310471057891846\n",
      "Loss: 1.666489839553833\n",
      "Loss: 2.290073871612549\n",
      "Loss: 1.9444037675857544\n",
      "Loss: 2.250920295715332\n",
      "Loss: 1.987201452255249\n",
      "Loss: 1.763353705406189\n",
      "Loss: 1.382371187210083\n",
      "Loss: 1.7346192598342896\n",
      "Loss: 1.3183852434158325\n",
      "Loss: 1.76865816116333\n",
      "Loss: 2.4599127769470215\n",
      "Loss: 1.6335598230361938\n",
      "Loss: 2.489868640899658\n",
      "Loss: 1.8663153648376465\n",
      "Loss: 1.9094758033752441\n",
      "Loss: 1.1594403982162476\n",
      "Loss: 1.836871862411499\n",
      "Loss: 1.6730403900146484\n",
      "Loss: 2.174039125442505\n",
      "Loss: 1.7375388145446777\n",
      "Loss: 2.4777235984802246\n",
      "Loss: 1.7759016752243042\n",
      "Loss: 1.6185446977615356\n",
      "Loss: 2.359898567199707\n",
      "Loss: 1.1410658359527588\n",
      "Loss: 1.7946887016296387\n",
      "Loss: 1.8456820249557495\n",
      "Loss: 1.9891225099563599\n",
      "Loss: 2.4020209312438965\n",
      "Loss: 1.512580156326294\n",
      "Loss: 1.325561761856079\n",
      "Loss: 1.3481820821762085\n",
      "Loss: 1.7081148624420166\n",
      "Loss: 0.7102383375167847\n",
      "Loss: 2.186718702316284\n",
      "Loss: 2.72537899017334\n",
      "Loss: 1.6256600618362427\n",
      "Loss: 1.16379714012146\n",
      "Loss: 1.8490403890609741\n",
      "Loss: 2.115206003189087\n",
      "Loss: 1.861204743385315\n",
      "Loss: 2.254361152648926\n",
      "Loss: 1.8461946249008179\n",
      "Loss: 0.8340187668800354\n",
      "Loss: 2.2824525833129883\n",
      "Loss: 1.8992271423339844\n",
      "Loss: 2.196603775024414\n",
      "Loss: 1.4811574220657349\n",
      "Loss: 1.0502023696899414\n",
      "Loss: 1.3243844509124756\n",
      "Loss: 1.6854125261306763\n",
      "Loss: 1.599822759628296\n",
      "Loss: 1.794796347618103\n",
      "Loss: 1.6096339225769043\n",
      "Loss: 2.0046401023864746\n",
      "Loss: 1.6252822875976562\n",
      "Loss: 2.267390251159668\n",
      "Loss: 1.2892274856567383\n",
      "Loss: 1.0289090871810913\n",
      "Loss: 1.8185536861419678\n",
      "Loss: 1.2754136323928833\n",
      "Loss: 2.2230358123779297\n",
      "Loss: 2.8546905517578125\n",
      "Loss: 1.7447313070297241\n",
      "Loss: 2.5122339725494385\n",
      "Loss: 1.6336076259613037\n",
      "Loss: 1.9977757930755615\n",
      "Loss: 2.3680601119995117\n",
      "Loss: 2.096062183380127\n",
      "Loss: 2.0954365730285645\n",
      "Loss: 1.4076608419418335\n",
      "Loss: 1.780993938446045\n",
      "Loss: 1.7050561904907227\n",
      "Loss: 3.4590048789978027\n",
      "Loss: 1.2718310356140137\n",
      "Loss: 1.5619711875915527\n",
      "Loss: 2.1409478187561035\n",
      "Loss: 1.2761532068252563\n",
      "Loss: 2.3561038970947266\n",
      "Loss: 1.470865249633789\n",
      "Loss: 0.61663419008255\n",
      "Loss: 1.9391605854034424\n",
      "Loss: 0.9716482758522034\n",
      "Loss: 1.5362226963043213\n",
      "Loss: 1.254173994064331\n",
      "Loss: 2.2906079292297363\n",
      "Loss: 1.7724149227142334\n",
      "Loss: 1.6671404838562012\n",
      "Loss: 3.1326279640197754\n",
      "Loss: 1.9800626039505005\n",
      "Loss: 0.6753740906715393\n",
      "Loss: 1.3895971775054932\n",
      "Loss: 1.9605333805084229\n",
      "Loss: 2.3066091537475586\n",
      "Loss: 1.7828047275543213\n",
      "Loss: 1.218973994255066\n",
      "Loss: 1.382997989654541\n",
      "Loss: 1.7082843780517578\n",
      "Loss: 0.9314853549003601\n",
      "Loss: 1.7375922203063965\n",
      "Loss: 2.5781781673431396\n",
      "Loss: 1.5804059505462646\n",
      "Loss: 1.7177746295928955\n",
      "Loss: 1.4540053606033325\n",
      "Loss: 1.7717149257659912\n",
      "Loss: 1.8184915781021118\n",
      "Loss: 0.6880011558532715\n",
      "Loss: 1.486359715461731\n",
      "Loss: 2.06254506111145\n",
      "Loss: 1.405153512954712\n",
      "Loss: 1.166704773902893\n",
      "Loss: 1.8703393936157227\n",
      "Loss: 1.9981940984725952\n",
      "Loss: 1.5663292407989502\n",
      "Loss: 0.8781736493110657\n",
      "Loss: 2.189345121383667\n",
      "Loss: 0.9973955750465393\n",
      "Loss: 0.9982305765151978\n",
      "Loss: 1.3536655902862549\n",
      "Loss: 2.011629104614258\n",
      "Loss: 1.8057551383972168\n",
      "Loss: 2.115665912628174\n",
      "Loss: 2.117880344390869\n",
      "Loss: 0.6499053239822388\n",
      "Loss: 1.6578155755996704\n",
      "Loss: 0.8098518252372742\n",
      "Loss: 1.8308281898498535\n",
      "Loss: 2.138143301010132\n",
      "Loss: 1.0813653469085693\n",
      "Loss: 1.1042672395706177\n",
      "Loss: 1.2617402076721191\n",
      "Loss: 1.6819294691085815\n",
      "Loss: 0.6484421491622925\n",
      "Loss: 1.4856271743774414\n",
      "Loss: 1.8570811748504639\n",
      "Loss: 2.185411214828491\n",
      "Loss: 1.9830853939056396\n",
      "Loss: 0.8079941868782043\n",
      "Loss: 2.5445444583892822\n",
      "Loss: 1.3798257112503052\n",
      "Loss: 1.0803194046020508\n",
      "Loss: 1.6395752429962158\n",
      "Loss: 2.3261632919311523\n",
      "Loss: 1.5291872024536133\n",
      "Loss: 2.2260940074920654\n",
      "Loss: 0.9848861694335938\n",
      "Loss: 1.3369154930114746\n",
      "Loss: 1.2493596076965332\n",
      "Loss: 0.7354381084442139\n",
      "Loss: 1.3095636367797852\n",
      "Loss: 1.8771229982376099\n",
      "Loss: 1.4322524070739746\n",
      "Loss: 0.8448476791381836\n",
      "Loss: 1.7211339473724365\n",
      "Loss: 1.0346665382385254\n",
      "Loss: 2.019817590713501\n",
      "Loss: 1.2889420986175537\n",
      "Loss: 1.45613694190979\n",
      "Loss: 1.2669768333435059\n",
      "Loss: 1.3183916807174683\n",
      "Loss: 1.783219575881958\n",
      "Loss: 1.318036675453186\n",
      "Loss: 1.267960548400879\n",
      "Loss: 1.1479047536849976\n",
      "Loss: 2.713270425796509\n",
      "Loss: 1.201690673828125\n",
      "Loss: 1.3515615463256836\n",
      "Loss: 0.8859142661094666\n",
      "Loss: 2.3744254112243652\n",
      "Loss: 1.1678826808929443\n",
      "Loss: 1.7337138652801514\n",
      "Loss: 1.8583590984344482\n",
      "Loss: 0.810259222984314\n",
      "Loss: 1.8394311666488647\n",
      "Loss: 1.2708792686462402\n",
      "Loss: 1.7955715656280518\n",
      "Loss: 1.197569727897644\n",
      "Loss: 1.2571208477020264\n",
      "Loss: 1.8285925388336182\n",
      "Loss: 1.1804091930389404\n",
      "Loss: 1.0116169452667236\n",
      "Loss: 1.5847429037094116\n",
      "Loss: 1.5236493349075317\n",
      "Loss: 0.9498489499092102\n",
      "Loss: 1.6338753700256348\n",
      "Loss: 0.9275500178337097\n",
      "Loss: 0.9055694937705994\n",
      "Loss: 0.8463993072509766\n",
      "Loss: 1.5022755861282349\n",
      "Loss: 2.378849983215332\n",
      "Loss: 0.5816847085952759\n",
      "Loss: 1.9993188381195068\n",
      "Loss: 2.439061164855957\n",
      "Loss: 1.3519891500473022\n",
      "Loss: 2.160438060760498\n",
      "Loss: 2.30619740486145\n",
      "Loss: 2.001328229904175\n",
      "Loss: 0.9140719771385193\n",
      "Loss: 1.4099725484848022\n",
      "Loss: 1.51171875\n",
      "Loss: 1.7271039485931396\n",
      "Loss: 1.545776128768921\n",
      "Loss: 1.5955196619033813\n",
      "Loss: 0.6520472764968872\n",
      "Loss: 2.455782651901245\n",
      "Loss: 1.6638418436050415\n",
      "Loss: 0.9738608002662659\n",
      "Loss: 1.9925835132598877\n",
      "Loss: 1.9334080219268799\n",
      "Loss: 1.190920114517212\n",
      "Loss: 1.6600457429885864\n",
      "Loss: 1.9648141860961914\n",
      "Loss: 1.334186315536499\n",
      "Loss: 0.9668115377426147\n",
      "Loss: 1.7790205478668213\n",
      "Loss: 2.919767379760742\n",
      "Loss: 1.057918906211853\n",
      "Loss: 1.4637181758880615\n",
      "Loss: 2.202120542526245\n",
      "Loss: 2.306776523590088\n",
      "Loss: 2.5686533451080322\n",
      "Loss: 1.6916803121566772\n",
      "Loss: 3.152379035949707\n",
      "Loss: 0.85862135887146\n",
      "Loss: 1.7054698467254639\n",
      "Loss: 1.1906074285507202\n",
      "Loss: 0.9549814462661743\n",
      "Loss: 0.6727789044380188\n",
      "Loss: 2.0932812690734863\n",
      "Loss: 0.8241435885429382\n",
      "Loss: 1.5236663818359375\n",
      "Loss: 3.795773983001709\n",
      "Loss: 1.4146448373794556\n",
      "Loss: 1.5509086847305298\n",
      "Loss: 1.8564618825912476\n",
      "Loss: 1.4378149509429932\n",
      "Loss: 1.533048391342163\n",
      "Loss: 0.9752871990203857\n",
      "Loss: 1.7182878255844116\n",
      "Loss: 0.9719315767288208\n",
      "Loss: 1.7681894302368164\n",
      "Loss: 1.5348011255264282\n",
      "Loss: 1.2126466035842896\n",
      "Loss: 2.136960744857788\n",
      "Loss: 0.4048571288585663\n",
      "Loss: 0.8157066106796265\n",
      "Loss: 1.2409019470214844\n",
      "Loss: 1.2644128799438477\n",
      "Loss: 1.3636903762817383\n",
      "Loss: 1.5364649295806885\n",
      "Loss: 1.2679675817489624\n",
      "Loss: 1.4481513500213623\n",
      "Loss: 1.2237746715545654\n",
      "Loss: 2.422903537750244\n",
      "Loss: 2.369169235229492\n",
      "Loss: 1.8014870882034302\n",
      "Loss: 2.269787549972534\n",
      "Loss: 1.3818458318710327\n",
      "Loss: 2.540379524230957\n",
      "Loss: 2.038257598876953\n",
      "Loss: 1.6697518825531006\n",
      "Loss: 1.0324759483337402\n",
      "Loss: 0.5370463132858276\n",
      "Loss: 1.5810084342956543\n",
      "Loss: 1.4654009342193604\n",
      "Loss: 1.5174226760864258\n",
      "Loss: 1.009031057357788\n",
      "Loss: 0.7603049278259277\n",
      "Loss: 2.0551071166992188\n",
      "Loss: 2.114048957824707\n",
      "Loss: 1.0142205953598022\n",
      "Loss: 2.41416335105896\n",
      "Loss: 1.8687444925308228\n",
      "Loss: 2.690617084503174\n",
      "Loss: 1.318440556526184\n",
      "Loss: 1.321549415588379\n",
      "Loss: 2.4512603282928467\n",
      "Loss: 1.5230231285095215\n",
      "Loss: 1.7118972539901733\n",
      "Loss: 1.6045722961425781\n",
      "Loss: 1.3547226190567017\n",
      "Loss: 1.5006660223007202\n",
      "Loss: 1.2358343601226807\n",
      "Loss: 0.9941699504852295\n",
      "Loss: 1.6433738470077515\n",
      "Loss: 2.178654432296753\n",
      "Loss: 1.7738440036773682\n",
      "Loss: 1.40001380443573\n",
      "Loss: 1.2719039916992188\n",
      "Loss: 1.490647315979004\n",
      "Loss: 1.7813938856124878\n",
      "Loss: 1.4773834943771362\n",
      "Loss: 1.8996895551681519\n",
      "Loss: 0.8267441987991333\n",
      "Loss: 1.8340505361557007\n",
      "Loss: 1.791010856628418\n",
      "Loss: 2.488762855529785\n",
      "Loss: 2.1137096881866455\n",
      "Loss: 1.1824326515197754\n",
      "Loss: 1.600174903869629\n",
      "Loss: 0.6094557046890259\n",
      "Loss: 1.0938003063201904\n",
      "Loss: 2.3183679580688477\n",
      "Loss: 1.4223856925964355\n",
      "Loss: 2.45350980758667\n",
      "Loss: 1.3488553762435913\n",
      "Loss: 0.9290847778320312\n",
      "Loss: 1.4399960041046143\n",
      "Loss: 1.2083749771118164\n",
      "Loss: 1.608541488647461\n",
      "Loss: 1.0697444677352905\n",
      "Loss: 1.0336805582046509\n",
      "Loss: 3.0711774826049805\n",
      "Loss: 0.8525749444961548\n",
      "Loss: 1.4380284547805786\n",
      "Loss: 1.973888874053955\n",
      "Loss: 1.6535242795944214\n",
      "Loss: 2.358555316925049\n",
      "Loss: 1.6222013235092163\n",
      "Loss: 1.8455241918563843\n",
      "Loss: 2.1168227195739746\n",
      "Loss: 1.5666139125823975\n",
      "Loss: 2.4748458862304688\n",
      "Loss: 1.3431611061096191\n",
      "Loss: 2.1669821739196777\n",
      "Loss: 1.0762102603912354\n",
      "Loss: 1.4546153545379639\n",
      "Loss: 1.853393793106079\n",
      "Loss: 1.5866457223892212\n",
      "Loss: 1.1334794759750366\n",
      "Loss: 1.8893061876296997\n",
      "Loss: 1.2025151252746582\n",
      "Loss: 1.3412857055664062\n",
      "Loss: 0.6790192127227783\n",
      "Loss: 1.2809219360351562\n",
      "Loss: 1.7738325595855713\n",
      "Loss: 1.388906478881836\n",
      "Loss: 0.8629217147827148\n",
      "Loss: 1.9262601137161255\n",
      "Loss: 1.1548634767532349\n",
      "Loss: 1.2639704942703247\n",
      "Loss: 1.189850926399231\n",
      "Loss: 1.2063932418823242\n",
      "Loss: 0.841267466545105\n",
      "Loss: 2.4962284564971924\n",
      "Loss: 1.244304895401001\n",
      "Loss: 1.5381147861480713\n",
      "Loss: 1.803397536277771\n",
      "Loss: 1.1360752582550049\n",
      "Loss: 1.3507355451583862\n",
      "Loss: 1.3509612083435059\n",
      "Loss: 1.6016709804534912\n",
      "Loss: 2.0120832920074463\n",
      "Loss: 1.3086439371109009\n",
      "Loss: 2.655440330505371\n",
      "Loss: 1.3941816091537476\n",
      "Loss: 1.8734426498413086\n",
      "Loss: 1.4511724710464478\n",
      "Loss: 1.0313851833343506\n",
      "Loss: 1.1809923648834229\n",
      "Loss: 1.6310176849365234\n",
      "Loss: 1.4147655963897705\n",
      "Loss: 1.1466023921966553\n",
      "Loss: 1.2861264944076538\n",
      "Loss: 1.5275421142578125\n",
      "Loss: 1.5186131000518799\n",
      "Loss: 1.9911248683929443\n",
      "Loss: 1.8116809129714966\n",
      "Loss: 1.6897516250610352\n",
      "Loss: 1.8025169372558594\n",
      "Loss: 1.6197770833969116\n",
      "Loss: 0.8686383962631226\n",
      "Loss: 0.9580641388893127\n",
      "Loss: 1.4784661531448364\n",
      "Loss: 1.0539675951004028\n",
      "Loss: 2.0787458419799805\n",
      "Loss: 1.3263094425201416\n",
      "Loss: 1.4753668308258057\n",
      "Loss: 0.9006732702255249\n",
      "Loss: 1.4572771787643433\n",
      "Loss: 1.066088318824768\n",
      "Loss: 1.5317952632904053\n",
      "Loss: 1.6133501529693604\n",
      "Loss: 1.024876594543457\n",
      "Loss: 1.1879781484603882\n",
      "Loss: 1.179373860359192\n",
      "Loss: 1.5576412677764893\n",
      "Loss: 1.6589971780776978\n",
      "Loss: 1.0228748321533203\n",
      "Loss: 1.4427822828292847\n",
      "Loss: 1.3699296712875366\n",
      "Loss: 1.1264287233352661\n",
      "Loss: 1.1134485006332397\n",
      "Loss: 0.6559775471687317\n",
      "Loss: 0.9570574760437012\n",
      "Loss: 1.4530022144317627\n",
      "Loss: 0.9472172260284424\n",
      "Loss: 1.0273247957229614\n",
      "Loss: 2.104966640472412\n",
      "Loss: 2.4383797645568848\n",
      "Loss: 2.081632137298584\n",
      "Loss: 0.4720604121685028\n",
      "Loss: 1.8134472370147705\n",
      "Loss: 1.431496500968933\n",
      "Loss: 1.3145461082458496\n",
      "Loss: 1.725616216659546\n",
      "Loss: 0.39530158042907715\n",
      "Loss: 1.6571686267852783\n",
      "Loss: 1.2965137958526611\n",
      "Loss: 0.6673738956451416\n",
      "Loss: 1.5347808599472046\n",
      "Loss: 1.2930376529693604\n",
      "Loss: 1.3161218166351318\n",
      "Loss: 1.260847568511963\n",
      "Loss: 0.7326796650886536\n",
      "Loss: 0.9521591067314148\n",
      "Loss: 1.1994391679763794\n",
      "Loss: 1.3901829719543457\n",
      "Loss: 1.1928433179855347\n",
      "Loss: 0.7449737191200256\n",
      "Loss: 0.6022471189498901\n",
      "Loss: 2.8709359169006348\n",
      "Loss: 0.9874750971794128\n",
      "Loss: 0.9372957944869995\n",
      "Loss: 1.2042030096054077\n",
      "Loss: 1.1950936317443848\n",
      "Loss: 0.6506767272949219\n",
      "Loss: 1.8964598178863525\n",
      "Loss: 1.5636907815933228\n",
      "Loss: 0.7274705171585083\n",
      "Loss: 0.9425230622291565\n",
      "Loss: 0.691927433013916\n",
      "Loss: 1.0628745555877686\n",
      "Loss: 1.1044243574142456\n",
      "Loss: 1.0551676750183105\n",
      "Loss: 1.6243114471435547\n",
      "Loss: 1.7353192567825317\n",
      "Loss: 0.2644701898097992\n",
      "Loss: 1.0627011060714722\n",
      "Loss: 2.6588895320892334\n",
      "Loss: 1.8255068063735962\n",
      "Loss: 1.2143340110778809\n",
      "Loss: 1.1580754518508911\n",
      "Loss: 1.4352174997329712\n",
      "Loss: 0.9293055534362793\n",
      "Loss: 1.0091043710708618\n",
      "Loss: 0.5476112365722656\n",
      "Loss: 1.180012583732605\n"
     ]
    }
   ],
   "source": [
    "num_classes = 12\n",
    "\n",
    "model = models.resnet50(pretrained=True)\n",
    "model.fc = torch.nn.Linear(2048, num_classes)  # Adjust output layer for your number of classes\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "# Move model to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Training loop (simplified)\n",
    "for images, labels in data_loader:\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(images)\n",
    "    loss = criterion(outputs, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print(\"Loss:\", loss.item())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524e44ae-d356-4699-95ec-3546246c40d6",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f4e52573-ee1f-48b5-9fc6-8e1cfc9f4732",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=12, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset = ScriptDataset(test[:100], transform=test_transform_pipeline, multiplier=1)  # No need for augmentation in testing\n",
    "test_loader = DataLoader(test_dataset, batch_size=4, shuffle=False)  # No shuffle for consistent evaluation\n",
    "\n",
    "model.eval()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9b175cd1-74cc-4482-97b6-cc0e85219f3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/rmirza/.conda/envs/datascience/lib/python3.13/site-packages/PIL/Image.py:3406: DecompressionBombWarning: Image size (92846289 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 27.00%\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():  # No gradients needed during evaluation\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        outputs = model(images)  # Get predictions\n",
    "        _, predicted = torch.max(outputs, 1)  # Convert logits to class indices\n",
    "\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "accuracy = correct / total * 100\n",
    "print(f\"Test Accuracy: {accuracy:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
